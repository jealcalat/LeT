%%
%% Author: jemanj
%% 3/29/19
%%

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{caption}
\usepackage[]{bm}
\usepackage{float}
\usepackage{xcolor}
\usepackage{tcolorbox} %para cajas de texto
\usepackage{sectsty}
\usepackage[sf,bf]{titlesec}

\definecolor{hd}{rgb}{0.2,0.2,0.7}
\definecolor{tit}{rgb}{0.1,0.4,0.7}

\sectionfont{\color{hd}}
\subsectionfont{\color{hd}}
\subsubsectionfont{\color{hd}}


\title{\color{tit} \textsf{\textbf{Learning to time (LeT): A tutorial}}}
%\subtitle{CEIC, Universidad de Guadalajara}
\author{\normalsize Emmanuel AlcalÃ¡\\
        \normalsize CEIC, Universidad de Guadalajara}
\date{\today}


% Document
\begin{document}

    \maketitle

    \section{States dynamics}

I based this manuscript in the paper by Machado, Malheiro and Erlhagen (2009).

LeT have three components:

    \begin{itemize}
        \item A series of (behavioral) states.
        \item Associative links connecting states to a operant response.
        \item The operant response.
    \end{itemize}

The states advance at a rate $\lambda$, which is a normal random variable.

    \[
        \lambda \sim \mathcal{N} (\mu, \sigma),\; \lambda > 0
    \]

    The symbol $\sim$ means "distributed as", and $\mathcal{N}$ is for the normal distribution with parameters
    $\mu$ and $\sigma$, not to be confused with the \textit{cumulative distribution function} \footnote{The authors use a different notation. For example, $N(x,\mu,\sigma)$ for the normal density function evaluated at $x$. This is a bit confusing since every density evaluated at $x$ is 0}.

Every $i$-th trial, a value $\lambda_i$ is sampled from $\mathcal{N}$ and the current state at $t$ is $N(t) = \lambda t$, that is,
the state at time $t$ is the product of the time elapsed and rate $\lambda$ (which is states/second).
Because $N$ must be an integer, the authors use a ceiling function to round $\lambda t$.
They define a ceiling function, denoted by $\lceil x \rceil$, like the \textit{smallest integer greater than $x$}.
That is,

    \[
        \lceil \lambda T \rceil = \lambda T + \varepsilon
    \]

So, for example, $\lceil 1.2 \rceil = 2$. The trial advance from $t = 1$ until $T$, the time of reinforcement, so that the
reinforced state is $N(t = T)$.
    The states transitions form the random process $N(t) = \lceil {\lambda t} \rceil$.
    The $N$ states starts at 1 and are activated serially.

There are no upper bound of the states that can be activated, so the limits of $N(t)$ are determined by $\mu$ and $\sigma$.
For example, if $\mu = 1$ \footnote{Which means the rate $\lambda$ most probable value is 1 state per second.} and $\sigma = 0.1$, the states will be very close to the true $T$, but if $\sigma = 0.6$,
there will be more reinforced states that are far from $T$, and $N(t)$ spans over a broader set of values.
Figure 1 shows a simulation with $\mu=1,\sigma=0.2$.
    Note that if $\mu > 1$ the mean of the reinforced states (dotted line in the histogram of Figure 1) will be shifted above $T$, or below if $\mu < 1$.

Thus, the reinforced states $N(t = T)_i$ (or $N(T)_i$ for short) of the $i$-th trials, is the vector
$\mathbf{N^*} = \boldsymbol{\lambda} T$.

    \begin{figure}[H]
            \centering
            \includegraphics[scale=0.7]{nt_let}
            \caption{Example of a process of 400 trials. The left panel shows the state transitions for every $\lambda$ sampled from the normal distribution (see the textbox inset). At $t = 40$, the reinforced states spread around the true value of $T$ (40 s), so they approximate a normal distribution with mean $\mu \times t$ and standard deviation $\sigma \times t$ (right panel).}
    \end{figure}

    The states below $N(t)$ are extinguished, and the states above are inactive.
    There is a $q(n,T)$ probability that the state $n$ is extinguished at $T$, and a probability $p(n,T)$ that it is reinforced.
    Also, there is a $r(n,T)$ probability that the $n$ state will be inactive (i.e., the trial will end before $T$, and
    state $n$ will not be reinforced nor extinguished).
    All need sum to 1, so that $p(n,T) = 1 - q(n,T) - r(n,T)$.

Because $n$ is extinguished if and only if (\textit{iif}) $n < N(T)$, so $q(n,T) = p(n < N(T))$,
and $N(T) = \lceil \lambda T \rceil$, we have

    \[
        q(n,T) = P \Big(\lambda > \frac{n}{T}\Big) = 1 - P(\lambda < \frac{n}{T}) = 1 - \Phi \Big (\frac{n}{T}, \mu, \sigma \Big)
    \]


On which $\Phi (\cdot)$ is the \textit{cumulative distribution function (CDF)}, or just \textit{distribution function}:

    \[
        \Phi \Big( \frac{n}{T}, \mu, \sigma \Big) = \frac{1}{\sigma \sqrt{2 \pi}} \int_{-\infty}^{\frac{n}{T}} \exp^{-(x - \mu)/2\sigma^2}dx
    \]

But since $t > 0$, we are just interested in evaluate the integral in the domain (0,$\frac{n}{T}$] \footnote{Of course,
    we should subtract first the integral of the domain $[-\infty, 0]$, but is a very small quantity, so it's negligible.}.
$\Phi$ doesn't have a closed form solution, and it's often approximated by Taylor expansion with

    \[
        \exp^{u} = \sum^{k=0}_{\infty} \frac{u^k}{k!}, \; \text{for } u = \frac{-(x - \mu)}{2 \sigma^2}
    \]

But we are modern people and will take advantage of the software.
Most statistical packages can compute CDFs.
Let's see an example.
If $\mu = 1, \sigma = 0.2, n = 15$
and $T = 40$, $q(15,40) = P \Big( \lambda > \frac{15}{40} \Big)$ or $1 - \Phi(\frac{15}{40},1,0.2)$. Using \textsf{Python}:

    \begin{verbatim}
        from scipy.stats import norm
        1 - norm.cdf(n/T,loc=1,scale=0.2)
    \end{verbatim}

Returns 0.734014, that is, the probability (actually, the density, or the area under the curve, etc) of state 35 being an extinguished state is about 74 \%.
    We can also interpret that quantity in terms of expected proportion of trials in which state 35 is \textit{not reinforced}.
    See Figure 2 for a graphical representation of this probability just calculated.

    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.7]{lambda_nT}
        \caption{Probability density function of a normal distribution with $\mu = 1, \sigma = 0.2$ for $t = 1,2,3..,40$.
        Shaded area shows the density $P(\lambda > 35/40)$, which means that is moderately probable that state 35
        is a extinguished state.}
    \end{figure}

    The state $n$ is inactive \textit{iif} $n > N(T)$, and, again, $N(T) = \lceil \lambda T \rceil$.
    Because $\lceil \lambda T \rceil$ is a quantity greater than $\lambda T$, we can express $n > \lceil \lambda T \rceil$
    as $n - 1 > \lambda T$ \footnote{This follows from the definition of the ceiling function.}.
    Then, the probability that $n$ is inactive, or $r(n,T)$, is

    \[
        r(n,T) = P(n > \lceil \lambda T \rceil) = P(n - 1 > \lambda T) = \Phi \Big( \frac{n-1}{T},\mu,\sigma \Big)
    \]

    Now, the expresion for the probability that $n$ will be reinforced can be expressed as

    \[
        p(n,T) = \Phi \Big ( \frac{n}{T}, \mu, \sigma \Big) - \Phi \Big ( \frac{n - 1}{T},\mu,\sigma \Big)
    \]

    In Machado, Malheiro and Erlhagen (2009) the authors provide an approximation of $p(n,T)$ without saying how they
    achieved that solution. The approximation is

    \[
        p(n,T) \approx \frac{1}{T} \phi_{\mu,\sigma} \Big(\frac{n}{T}\Big)
    \]
    On which $\phi_{\mu,\sigma}(\frac{n}{T})$ is the normal probability density function (pdf\footnote{Note that the notation for the CDF and the pdf is different: we use bold capital letters for the CDF, and lowercase letters for the pdf}) evaluated at $\frac{n}{T}$.
    One way to get into this is by the following reasoning. The CDFs above can be rewritten as a definite integral

    \begin{align*}
        p(n,T) &= \Phi \Big ( \frac{n}{T}, \mu, \sigma \Big) - \Phi \Big ( \frac{n - 1}{T},\mu,\sigma \Big)\\
               &= \int_{\frac{n-1}{T}}^{\frac{n}{T}} \phi_{\mu,\sigma}(x)dx\\
    \end{align*}

    If we approximate $\phi_{\mu,\sigma}$ by taking the upper value of the definite integral, $x = \frac{n}{T}$, and
    since this is a constant (the pdf evaluated ad the upper limit): we have

    \begin{align*}
        p(n,T) &= \int_{\frac{n-1}{T}}^{\frac{n}{T}} \phi_{\mu,\sigma} \Big( \frac{n}{T} \Big)dx\\
               &= \phi_{\mu,\sigma} \Big (\frac{n}{T} \Big)\int_{\frac{n-1}{T}}^{\frac{n}{T}}dx \\
               &= \phi_{\mu,\sigma} \Big (\frac{n}{T} \Big) \Big (\frac{n}{T} - \frac{n-1}{T} \Big) \\
        \text{Rearenging:} \\
        p(n,T)  &= \Big (\frac{1}{T} \Big) \phi_{\mu,\sigma}  \Big (\frac{n}{T} \Big) \\
        \text{Q.E.D}
    \end{align*}

%    From the above equation, the authors derive the scalar property.
%
%    \[
%        cv
%    \]
\end{document}